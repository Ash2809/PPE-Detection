{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Hardhats, 3 NO-Safety Vests, 4 Persons, 1 machinery, 54.7ms\n",
      "Speed: 6.0ms preprocess, 54.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Hardhats, 3 NO-Safety Vests, 3 Persons, 1 machinery, 43.9ms\n",
      "Speed: 6.0ms preprocess, 43.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Hardhats, 1 NO-Mask, 3 NO-Safety Vests, 5 Persons, 44.0ms\n",
      "Speed: 5.0ms preprocess, 44.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Hardhats, 1 NO-Mask, 3 NO-Safety Vests, 3 Persons, 44.8ms\n",
      "Speed: 6.0ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Hardhats, 1 NO-Mask, 3 NO-Safety Vests, 4 Persons, 44.7ms\n",
      "Speed: 5.0ms preprocess, 44.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Hardhats, 1 Mask, 1 NO-Mask, 3 NO-Safety Vests, 3 Persons, 44.3ms\n",
      "Speed: 5.9ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Hardhats, 1 Mask, 1 NO-Mask, 3 NO-Safety Vests, 3 Persons, 44.7ms\n",
      "Speed: 4.1ms preprocess, 44.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Hardhats, 1 NO-Mask, 3 NO-Safety Vests, 3 Persons, 44.3ms\n",
      "Speed: 5.4ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 4 Persons, 44.0ms\n",
      "Speed: 4.0ms preprocess, 44.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Hardhats, 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 3 Persons, 44.2ms\n",
      "Speed: 5.0ms preprocess, 44.2ms inference, 24.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 3 Persons, 44.9ms\n",
      "Speed: 4.3ms preprocess, 44.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Hardhats, 4 NO-Safety Vests, 3 Persons, 45.1ms\n",
      "Speed: 5.1ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(r\"ppe.pt\")\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\aashutosh kumar\\Downloads\\Workers.mp4\")\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "classNames = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone',\n",
    "              'Safety Vest', 'machinery', 'vehicle']\n",
    "color = (15,167,243)\n",
    "while True:\n",
    "    r, frame = cap.read()\n",
    "\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame,(720,720))\n",
    "        results = model(frame, stream = True)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                class_id = int(box.cls[0])\n",
    "                current_class = classNames[class_id]\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                if confidence > 0.1:\n",
    "                    if current_class == \"NO-Hardhat\" or current_class == \"NO-Mask\" or current_class == \"NO-Safety Vest\":\n",
    "                        color = (0,0,255)\n",
    "                    elif current_class == \"Hardhat\" or current_class or \"Mask\" or current_class == \"Safety Vest\":\n",
    "                        color = (0,255,0)\n",
    "\n",
    "                    elif current_class == \"Hardhat\" or current_class == \"Safety Vest\" or current_class == \"NO-Mask\":\n",
    "                        color = (15,241,249)\n",
    "                        \n",
    "                    cv2.rectangle(frame, (x1,y1), (x2,y2), color, 1)\n",
    "                    label = f\"{current_class}\"\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 1)\n",
    "\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Window\", frame)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(frame, (x1,y1), (x2,y2), (0,0,255), 2) \n",
    "                label = f\"{current_class},{confidence}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
